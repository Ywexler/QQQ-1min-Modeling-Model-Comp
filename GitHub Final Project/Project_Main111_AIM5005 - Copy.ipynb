{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV,train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path= \"C:/Users/ywexl/OneDrive/Desktop/AIM_5005/QQQ_1min.csv\" # Path to your CSV file\n",
    "\n",
    "# Calculate RSI Feature\n",
    "def compute_rsi(series, period=14):\n",
    "    delta = series.diff()  \n",
    "    gain = delta.clip(lower=0)      \n",
    "    loss = -1 * delta.clip(upper=0) \n",
    "\n",
    "    avg_gain = gain.rolling(window=period).mean()\n",
    "    avg_loss = loss.rolling(window=period).mean()\n",
    "\n",
    "    rs = avg_gain / (avg_loss + 1e-10)\n",
    "\n",
    "    rsi = 100 - (100 / (1.0 + rs))\n",
    "    return rsi\n",
    "\n",
    "\n",
    "def load_and_engineer(csv_path,short_window=5, long_window=15, rsi_period=14):\n",
    "   # Load Data\n",
    "   df= pd.read_csv(csv_path, parse_dates=['Datetime'], index_col='Datetime')\n",
    "   df = df.sort_index()\n",
    "\n",
    "   for col in ['Open', 'High', 'Low', 'Close']:\n",
    "      df[col] = df[col].astype(str).str.replace(r'[^0-9.]', '', regex=True).pipe(pd.to_numeric, errors='coerce')\n",
    "   df['Volume']=pd.to_numeric(df['Volume'], errors='coerce').fillna(0).astype(int)\n",
    "   df['Close_next']=df['Close'].shift(-1)\n",
    "   df.dropna(subset=['Close', 'Close_next'], inplace=True)\n",
    "   df['Target'] = (df['Close_next'] > df['Close']).astype(int)\n",
    "#features:\n",
    "   df['sma_short'] = df['Close'].rolling(window=short_window).mean()\n",
    "   df['sma_long'] = df['Close'].rolling(window=long_window).mean()\n",
    "   df['rolling_std'] = df['Close'].rolling(window=short_window).std()\n",
    "   df['ema_short'] = df['Close'].ewm(span=short_window, adjust=False).mean()\n",
    "   df['ema_long'] = df['Close'].ewm(span=long_window, adjust=False).mean()\n",
    "   df['Volume_Ratio_short'] = df['Volume'].rolling(window=5).mean() / df['Volume'].rolling(window=15).mean()\n",
    "   df['Volume_Ratio_long'] = df['Volume'].rolling(window=15).mean() / df['Volume'].rolling(window=30).mean()\n",
    "\n",
    "   df['RSI'] = compute_rsi(df['Close'], rsi_period)\n",
    "\n",
    "   df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "   feature_cols=[\n",
    "      'sma_short',\n",
    "      'sma_long',\n",
    "      'rolling_std',\n",
    "      'ema_short',\n",
    "      'ema_long',\n",
    "      'Volume_Ratio_short',\n",
    "      'Volume_Ratio_long',\n",
    "      'RSI'\n",
    "      ]\n",
    "   x=df[feature_cols].copy()\n",
    "   y=df['Target'].copy()\n",
    "   return x, y, df\n",
    "\n",
    "\n",
    "feature_sets = {\n",
    "    'Base (SMA & RSI)': [\n",
    "        'sma_short', 'sma_long', 'rolling_std', 'RSI'\n",
    "    ],\n",
    "    'With ema': [\n",
    "        'sma_short', 'sma_long', 'rolling_std', 'RSI',\n",
    "        'ema_short', 'ema_long'\n",
    "    ],\n",
    "    'With ema + Volume': [\n",
    "        'sma_short', 'sma_long', 'rolling_std', 'RSI',\n",
    "        'ema_short', 'ema_long',\n",
    "        'Volume_Ratio_short', 'Volume_Ratio_long'\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base (SMA & RSI) → (1920, 4)\n",
      "With ema → (1920, 6)\n",
      "With ema + Volume → (1920, 8)\n"
     ]
    }
   ],
   "source": [
    "X_all, y, df = load_and_engineer(csv_path)\n",
    "for name, cols in feature_sets.items():\n",
    "    print(name, \"→\", X_all[cols].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, X, y, df, test_frac=0.2):\n",
    "    split= int(len(X)*(1-test_frac))\n",
    "    X_train=X.iloc[:split]\n",
    "    X_test=X.iloc[split:]\n",
    "    y_train=y.iloc[:split]\n",
    "    y_test=y.iloc[split:]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred=model.predict(X_test)\n",
    "    print(f\"\\n=== {model.__class__.__name__} ===\")\n",
    "    print(classification_report(y_test, y_pred))   \n",
    "\n",
    "    backtest=df.iloc[split:].copy()\n",
    "    backtest[\"BarRet\"]= backtest[\"Close\"].pct_change().fillna(0)\n",
    "    backtest[\"StrategyRet\"]= backtest[\"BarRet\"]*y_pred\n",
    "    strategy_ret= (1+backtest[\"StrategyRet\"]).cumprod().iloc[-1]-1\n",
    "    bh_return= (1+backtest[\"BarRet\"]).cumprod().iloc[-1]-1\n",
    "    return strategy_ret, bh_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest ===\n",
      "\n",
      "=== RandomForestClassifier ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.55      0.49       181\n",
      "           1       0.48      0.37      0.42       203\n",
      "\n",
      "    accuracy                           0.46       384\n",
      "   macro avg       0.46      0.46      0.45       384\n",
      "weighted avg       0.46      0.46      0.45       384\n",
      "\n",
      "\n",
      "=== RandomForestClassifier ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.53      0.48       181\n",
      "           1       0.47      0.37      0.42       203\n",
      "\n",
      "    accuracy                           0.45       384\n",
      "   macro avg       0.45      0.45      0.45       384\n",
      "weighted avg       0.45      0.45      0.44       384\n",
      "\n",
      "\n",
      "=== RandomForestClassifier ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.55      0.49       181\n",
      "           1       0.50      0.40      0.45       203\n",
      "\n",
      "    accuracy                           0.47       384\n",
      "   macro avg       0.47      0.48      0.47       384\n",
      "weighted avg       0.48      0.47      0.47       384\n",
      "\n",
      "\n",
      "=== Logistic Regression ===\n",
      "\n",
      "=== LogisticRegression ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.46      0.48       181\n",
      "           1       0.54      0.57      0.56       203\n",
      "\n",
      "    accuracy                           0.52       384\n",
      "   macro avg       0.52      0.52      0.52       384\n",
      "weighted avg       0.52      0.52      0.52       384\n",
      "\n",
      "\n",
      "=== LogisticRegression ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.45      0.47       181\n",
      "           1       0.54      0.58      0.56       203\n",
      "\n",
      "    accuracy                           0.52       384\n",
      "   macro avg       0.52      0.52      0.52       384\n",
      "weighted avg       0.52      0.52      0.52       384\n",
      "\n",
      "\n",
      "=== LogisticRegression ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.52      0.50       181\n",
      "           1       0.54      0.50      0.52       203\n",
      "\n",
      "    accuracy                           0.51       384\n",
      "   macro avg       0.51      0.51      0.51       384\n",
      "weighted avg       0.51      0.51      0.51       384\n",
      "\n",
      "\n",
      "=== XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ywexl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:10:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ywexl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:10:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ywexl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:10:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGBClassifier ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.55      0.50       181\n",
      "           1       0.51      0.42      0.46       203\n",
      "\n",
      "    accuracy                           0.48       384\n",
      "   macro avg       0.49      0.49      0.48       384\n",
      "weighted avg       0.49      0.48      0.48       384\n",
      "\n",
      "\n",
      "=== XGBClassifier ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.55      0.50       181\n",
      "           1       0.52      0.44      0.48       203\n",
      "\n",
      "    accuracy                           0.49       384\n",
      "   macro avg       0.49      0.49      0.49       384\n",
      "weighted avg       0.49      0.49      0.49       384\n",
      "\n",
      "\n",
      "=== XGBClassifier ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.50      0.48       181\n",
      "           1       0.51      0.47      0.49       203\n",
      "\n",
      "    accuracy                           0.48       384\n",
      "   macro avg       0.49      0.49      0.48       384\n",
      "weighted avg       0.49      0.48      0.48       384\n",
      "\n",
      "\n",
      "=== Naive Bayes ===\n",
      "\n",
      "=== GaussianNB ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.64      0.56       181\n",
      "           1       0.56      0.41      0.48       203\n",
      "\n",
      "    accuracy                           0.52       384\n",
      "   macro avg       0.53      0.53      0.52       384\n",
      "weighted avg       0.53      0.52      0.52       384\n",
      "\n",
      "\n",
      "=== GaussianNB ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.58      0.53       181\n",
      "           1       0.55      0.46      0.50       203\n",
      "\n",
      "    accuracy                           0.52       384\n",
      "   macro avg       0.52      0.52      0.52       384\n",
      "weighted avg       0.52      0.52      0.51       384\n",
      "\n",
      "\n",
      "=== GaussianNB ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.57      0.53       181\n",
      "           1       0.56      0.48      0.52       203\n",
      "\n",
      "    accuracy                           0.53       384\n",
      "   macro avg       0.53      0.53      0.53       384\n",
      "weighted avg       0.53      0.53      0.53       384\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "feature_set",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "strategy_return",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "buy_hold_return",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "30f49e9b-3b6c-4f12-ba21-4e86b95869df",
       "rows": [
        [
         "0",
         "Random Forest",
         "Base (SMA & RSI)",
         "-0.00010370683675076098",
         "0.016629678007789472"
        ],
        [
         "1",
         "Random Forest",
         "With ema",
         "0.000572225107267732",
         "0.016629678007789472"
        ],
        [
         "2",
         "Random Forest",
         "With ema + Volume",
         "0.0001975183008464665",
         "0.016629678007789472"
        ],
        [
         "3",
         "Logistic Regression",
         "Base (SMA & RSI)",
         "0.0007067536348470682",
         "0.016629678007789472"
        ],
        [
         "4",
         "Logistic Regression",
         "With ema",
         "-0.004965911634956188",
         "0.016629678007789472"
        ],
        [
         "5",
         "Logistic Regression",
         "With ema + Volume",
         "-0.004319635399402499",
         "0.016629678007789472"
        ],
        [
         "6",
         "XGBoost",
         "Base (SMA & RSI)",
         "0.005011021287869566",
         "0.016629678007789472"
        ],
        [
         "7",
         "XGBoost",
         "With ema",
         "0.0038485611794027985",
         "0.016629678007789472"
        ],
        [
         "8",
         "XGBoost",
         "With ema + Volume",
         "0.00308754115761678",
         "0.016629678007789472"
        ],
        [
         "9",
         "Naive Bayes",
         "Base (SMA & RSI)",
         "0.007929781354941712",
         "0.016629678007789472"
        ],
        [
         "10",
         "Naive Bayes",
         "With ema",
         "0.007651239849356006",
         "0.016629678007789472"
        ],
        [
         "11",
         "Naive Bayes",
         "With ema + Volume",
         "0.00781254842291168",
         "0.016629678007789472"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>strategy_return</th>\n",
       "      <th>buy_hold_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Base (SMA &amp; RSI)</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>0.01663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>With ema</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.01663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>With ema + Volume</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.01663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Base (SMA &amp; RSI)</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.01663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>With ema</td>\n",
       "      <td>-0.004966</td>\n",
       "      <td>0.01663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>With ema + Volume</td>\n",
       "      <td>-0.004320</td>\n",
       "      <td>0.01663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Base (SMA &amp; RSI)</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>0.01663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>With ema</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>0.01663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>With ema + Volume</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>0.01663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Base (SMA &amp; RSI)</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.01663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>With ema</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>0.01663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>With ema + Volume</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.01663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model        feature_set  strategy_return  buy_hold_return\n",
       "0         Random Forest   Base (SMA & RSI)        -0.000104          0.01663\n",
       "1         Random Forest           With ema         0.000572          0.01663\n",
       "2         Random Forest  With ema + Volume         0.000198          0.01663\n",
       "3   Logistic Regression   Base (SMA & RSI)         0.000707          0.01663\n",
       "4   Logistic Regression           With ema        -0.004966          0.01663\n",
       "5   Logistic Regression  With ema + Volume        -0.004320          0.01663\n",
       "6               XGBoost   Base (SMA & RSI)         0.005011          0.01663\n",
       "7               XGBoost           With ema         0.003849          0.01663\n",
       "8               XGBoost  With ema + Volume         0.003088          0.01663\n",
       "9           Naive Bayes   Base (SMA & RSI)         0.007930          0.01663\n",
       "10          Naive Bayes           With ema         0.007651          0.01663\n",
       "11          Naive Bayes  With ema + Volume         0.007813          0.01663"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all, y, df = load_and_engineer(csv_path)\n",
    "\n",
    "models =[\n",
    "    (\"Random Forest\", RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    (\"Logistic Regression\", LogisticRegression(max_iter=1000, random_state=42)),\n",
    "    (\"XGBoost\", XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)),\n",
    "    (\"Naive Bayes\", GaussianNB())\n",
    "]\n",
    "results = []\n",
    "for model_name,model in models:\n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    for fs_name, cols in feature_sets.items():\n",
    "        X_fs= X_all[cols]\n",
    "        strategy_ret, bh_ret= run_model(model, X_fs, y, df)\n",
    "        results.append({\n",
    "            \"model\": model_name,\n",
    "            \"feature_set\": fs_name,\n",
    "            \"strategy_return\": strategy_ret,\n",
    "            \"buy_hold_return\": bh_ret\n",
    "        })\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trade_simulation(df, feature_sets, model_grids, test_size=0.2, n_splits=5, tcost=0.0):\n",
    "    summary_results = []\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    df=df.sort_index()\n",
    "    df[\"Return\"] = df[\"Close\"].pct_change().fillna(0)\n",
    "    for fs_name, cols in feature_sets.items():\n",
    "        X= df[cols]\n",
    "        y= df[\"Target\"]\n",
    "\n",
    "        split= int(len(X)*(1-test_size))\n",
    "        X_train, X_test= X.iloc[:split], X.iloc[split:]\n",
    "        y_train, y_test= y.iloc[:split], y.iloc[split:]\n",
    "        df_test= df.loc[X_test.index].copy()\n",
    "\n",
    "        for model_name,estimator, param_grid in model_grids:\n",
    "            gs=GridSearchCV(estimator, param_grid, cv=tscv, scoring=\"accuracy\", n_jobs=-1, verbose=0)\n",
    "            gs.fit(X_train, y_train)\n",
    "            df_test[\"signal\"]= gs.predict(X_test)\n",
    "            df_test[\"signal_prev\"]= df_test[\"signal\"].shift(1).fillna(0).astype(int)\n",
    "\n",
    "            entries=df_test[\n",
    "                (df_test[\"signal_prev\"]==0) & (df_test[\"signal\"]==1)].index\n",
    "            exits=df_test[\n",
    "                (df_test[\"signal_prev\"]==1) & (df_test[\"signal\"]==0)].index\n",
    "\n",
    "            if len(entries) and len(exits) and exits[0]<entries[0]:\n",
    "                exits=exits[1:]\n",
    "            if len(entries) and len(exits) and exits[-1]<entries[-1]:\n",
    "                exits=exits.append(pd.Index([df_test.index[-1]]))\n",
    "            pairs=list(zip(entries, exits))\n",
    "\n",
    "            pnls=[]\n",
    "            for entry, exit in pairs:\n",
    "                entry_price= df_test.loc[entry, \"Close\"]*(1+tcost)\n",
    "                exit_price= df_test.loc[exit, \"Close\"]*(1-tcost)\n",
    "                pnls.append((exit_price/entry_price)-1)\n",
    "        \n",
    "            total_return= np.prod([1+pnl for pnl in pnls])-1 if pnls else 0\n",
    "            num_trades= len(pnls)\n",
    "            avg_trade_return= np.mean(pnls) if pnls else 0\n",
    "            win_rate= np.mean(np.array(pnls)>0) if pnls else 0\n",
    "            average_pnl= np.mean(pnls) if pnls else 0\n",
    "            accuracy= accuracy_score(y_test, df_test[\"signal\"])\n",
    "\n",
    "            summary_results.append({\n",
    "                \"model\": model_name,\n",
    "                \"feature_set\": fs_name,\n",
    "                \"total_return\": total_return,\n",
    "                \"num_trades\": num_trades,\n",
    "                \"avg_trade_return\": avg_trade_return,\n",
    "                \"win_rate\": win_rate,\n",
    "                \"average_pnl\": average_pnl,\n",
    "                \"accuracy\": accuracy\n",
    "            })\n",
    "    return pd.DataFrame(summary_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid  = {'n_estimators': [50,100,200]}\n",
    "lr_param_grid  = {'C': [0.01,0.1,1]}\n",
    "xgb_param_grid = {'max_depth': [3,5], 'learning_rate':[0.01,0.1]}\n",
    "nb_param_grid  = {}  # no hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_grids = [\n",
    "    (\"Random Forest\",       RandomForestClassifier(random_state=42), rf_param_grid),\n",
    "    (\"Logistic Regression\", LogisticRegression(solver=\"liblinear\", random_state=42), lr_param_grid),\n",
    "    (\"XGBoost\",             XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42), xgb_param_grid),\n",
    "    (\"Naive Bayes\",         GaussianNB(), nb_param_grid)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ywexl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [15:13:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ywexl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [15:13:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ywexl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [15:13:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "feature_set",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "total_return",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_trades",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "avg_trade_return",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "win_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "average_pnl",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "accuracy",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "be117858-8cef-46e9-8a7a-283bef296149",
       "rows": [
        [
         "0",
         "Random Forest",
         "Base (SMA & RSI)",
         "0.0037256909594332033",
         "56",
         "6.673066634184377e-05",
         "0.5714285714285714",
         "6.673066634184377e-05",
         "0.46875"
        ],
        [
         "1",
         "Logistic Regression",
         "Base (SMA & RSI)",
         "0.00807372936548778",
         "21",
         "0.00038343168603829783",
         "0.6666666666666666",
         "0.00038343168603829783",
         "0.4869791666666667"
        ],
        [
         "2",
         "XGBoost",
         "Base (SMA & RSI)",
         "0.008424627103352345",
         "62",
         "0.0001358195861823959",
         "0.5",
         "0.0001358195861823959",
         "0.4817708333333333"
        ],
        [
         "3",
         "Naive Bayes",
         "Base (SMA & RSI)",
         "0.010005337437183126",
         "7",
         "0.001426053867049288",
         "0.5714285714285714",
         "0.001426053867049288",
         "0.5208333333333334"
        ],
        [
         "4",
         "Random Forest",
         "With ema",
         "-0.0003775070497342714",
         "47",
         "-7.621752806587961e-06",
         "0.5106382978723404",
         "-7.621752806587961e-06",
         "0.4375"
        ],
        [
         "5",
         "Logistic Regression",
         "With ema",
         "0.007829059117005821",
         "21",
         "0.00037192053338985787",
         "0.6666666666666666",
         "0.00037192053338985787",
         "0.4869791666666667"
        ],
        [
         "6",
         "XGBoost",
         "With ema",
         "0.01116127213703666",
         "58",
         "0.00019196372252109657",
         "0.5862068965517241",
         "0.00019196372252109657",
         "0.4895833333333333"
        ],
        [
         "7",
         "Naive Bayes",
         "With ema",
         "0.010164615915570163",
         "4",
         "0.0025381052627154177",
         "1.0",
         "0.0025381052627154177",
         "0.515625"
        ],
        [
         "8",
         "Random Forest",
         "With ema + Volume",
         "0.0039009868255228675",
         "39",
         "0.00010037796264733414",
         "0.5128205128205128",
         "0.00010037796264733414",
         "0.4661458333333333"
        ],
        [
         "9",
         "Logistic Regression",
         "With ema + Volume",
         "0.0030114860120651343",
         "22",
         "0.00013710878486813204",
         "0.6363636363636364",
         "0.00013710878486813204",
         "0.4817708333333333"
        ],
        [
         "10",
         "XGBoost",
         "With ema + Volume",
         "0.007134505650198131",
         "26",
         "0.00027459049834527294",
         "0.5384615384615384",
         "0.00027459049834527294",
         "0.4895833333333333"
        ],
        [
         "11",
         "Naive Bayes",
         "With ema + Volume",
         "0.010856821600824684",
         "7",
         "0.0015494816549539595",
         "0.7142857142857143",
         "0.0015494816549539595",
         "0.5260416666666666"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>total_return</th>\n",
       "      <th>num_trades</th>\n",
       "      <th>avg_trade_return</th>\n",
       "      <th>win_rate</th>\n",
       "      <th>average_pnl</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Base (SMA &amp; RSI)</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>56</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Base (SMA &amp; RSI)</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.486979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Base (SMA &amp; RSI)</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>62</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.481771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Base (SMA &amp; RSI)</td>\n",
       "      <td>0.010005</td>\n",
       "      <td>7</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.520833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>With ema</td>\n",
       "      <td>-0.000378</td>\n",
       "      <td>47</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>With ema</td>\n",
       "      <td>0.007829</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.486979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>With ema</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>58</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.489583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>With ema</td>\n",
       "      <td>0.010165</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>With ema + Volume</td>\n",
       "      <td>0.003901</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.466146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>With ema + Volume</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.481771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>With ema + Volume</td>\n",
       "      <td>0.007135</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.489583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>With ema + Volume</td>\n",
       "      <td>0.010857</td>\n",
       "      <td>7</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.526042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model        feature_set  total_return  num_trades  \\\n",
       "0         Random Forest   Base (SMA & RSI)      0.003726          56   \n",
       "1   Logistic Regression   Base (SMA & RSI)      0.008074          21   \n",
       "2               XGBoost   Base (SMA & RSI)      0.008425          62   \n",
       "3           Naive Bayes   Base (SMA & RSI)      0.010005           7   \n",
       "4         Random Forest           With ema     -0.000378          47   \n",
       "5   Logistic Regression           With ema      0.007829          21   \n",
       "6               XGBoost           With ema      0.011161          58   \n",
       "7           Naive Bayes           With ema      0.010165           4   \n",
       "8         Random Forest  With ema + Volume      0.003901          39   \n",
       "9   Logistic Regression  With ema + Volume      0.003011          22   \n",
       "10              XGBoost  With ema + Volume      0.007135          26   \n",
       "11          Naive Bayes  With ema + Volume      0.010857           7   \n",
       "\n",
       "    avg_trade_return  win_rate  average_pnl  accuracy  \n",
       "0           0.000067  0.571429     0.000067  0.468750  \n",
       "1           0.000383  0.666667     0.000383  0.486979  \n",
       "2           0.000136  0.500000     0.000136  0.481771  \n",
       "3           0.001426  0.571429     0.001426  0.520833  \n",
       "4          -0.000008  0.510638    -0.000008  0.437500  \n",
       "5           0.000372  0.666667     0.000372  0.486979  \n",
       "6           0.000192  0.586207     0.000192  0.489583  \n",
       "7           0.002538  1.000000     0.002538  0.515625  \n",
       "8           0.000100  0.512821     0.000100  0.466146  \n",
       "9           0.000137  0.636364     0.000137  0.481771  \n",
       "10          0.000275  0.538462     0.000275  0.489583  \n",
       "11          0.001549  0.714286     0.001549  0.526042  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_all, _, df = load_and_engineer(csv_path)\n",
    "trade_df = run_trade_simulation(df, feature_sets, model_grids)\n",
    "display(trade_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
